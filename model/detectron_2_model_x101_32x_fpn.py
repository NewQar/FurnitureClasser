# -*- coding: utf-8 -*-
"""detectron 2_model_X101_32X_FPN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/102rIGhNg9xKg42pDP5lsa_pl0nnIZChi
"""

# install dependencies: (use cu101 because colab has CUDA 10.1)
!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html 
!pip install cython pyyaml==5.1
!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'
import torch, torchvision
print(torch.__version__, torch.cuda.is_available())
!gcc --version
# opencv is pre-installed on colab

!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html

# You may need to restart your runtime prior to this, to let your installation take effect
# Some basic setup:
# Setup detectron2 logger
import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

# import some common libraries
import numpy as np
import cv2
import random
from google.colab.patches import cv2_imshow

# import some common detectron2 utilities
from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog
from detectron2.data.catalog import DatasetCatalog
import os

from google.colab import drive

drive.mount('/content/drive')

def load_json_labels(image_folder):
  from detectron2.structures import BoxMode
   # """
   # Returns Detectron2 style labels of images in image_folder based on JSON label file in image_folder.
    
    #TODO -- Maybe create some verbosity here? AKA, what are the outputs?
    #TODO -- what if annotations = None? Can we create a call to create an annotations CSV in 1 hit?
    
    #Params
   # ------
   # image_folder (str): target folder containing images
    #"""
    # Get absolute path of JSON label file
  for file in os.listdir(image_folder):
    if file.endswith(".json"):
      json_file = os.path.join(image_folder, file)

  # TODO: Fix this assertion
  assert json_file, "No .json label file found, please make one with annots_to_json()"

  with open(json_file, "r") as f:
    img_dicts = json.load(f)

  # Convert bbox_mode to Enum of BoxMode.XYXY_ABS (doesn't work loading normal from JSON)
  for img_dict in img_dicts:
    for annot in img_dict["annotations"]:
      annot["bbox_mode"] = BoxMode.XYXY_ABS

  return img_dicts

from detectron2.data import DatasetCatalog, MetadataCatalog

def register_datasets(train_path,test_path, valid_path=None, target_classes=None):
  """
  Registers a Detectron2 style dataset from training paths.

  Params
  ------
  train_path (str) : pathname to training data containing training images
  valid_path (str) : pathname to validation data containing validation images
  """
  # TODO - update to accept any kind of path, e.g. not only coffeemaker, maybe could take a dict as input?
  # E.g. {"training": "path/to/training",
  #          "valid": "path/to/valid"}
  for d in [train_path,test_path, valid_path]:
    dataset_name = d.split("/")[-1]
    #print("Registering: {}".format(dataset_name))
    DatasetCatalog.register(dataset_name, lambda d=d: load_json_labels(d))
    MetadataCatalog.get(dataset_name).set(thing_classes=target_classes)
  return MetadataCatalog.get(dataset_name)

# path for json file to gegister dataset

train_path='/content/drive/MyDrive/Colab Notebooks/airbnb-amenity-detection/training_data/all-final-train-20201208-1500perClass-8765'
test_path='/content/drive/MyDrive/Colab Notebooks/airbnb-amenity-detection/training_data/all-final-test-20201208-300perClass-1254'
valid_path='/content/drive/MyDrive/Colab Notebooks/airbnb-amenity-detection/training_data/all-final-validation-20201208-100perClass-442'

from detectron2.structures import BoxMode
import os
import json

test_img_dicts = load_json_labels(test_path)
train_img_dicts = load_json_labels(train_path)
val_img_dicts=load_json_labels(valid_path)

target_classess=['Bed', 'Cabinetry', 'Chair', 'Couch', 'Lamp', 'Table']      # class of object to be identify

furniture_data_metadata= register_datasets(train_path=train_path,test_path=test_path, # register dataset
                                            valid_path=valid_path,
                                            target_classes=target_classess)

cfg = get_cfg()
# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library
cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml"))

# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well
cfg.MODEL.WEIGHTS ="/content/drive/MyDrive/capstone/phase 1/model/X101 FPN/model_model_faster_rcnn_X_101_32x8d_FPN_3x_9000iter_final_forRainfield.pth"
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6       # model identify 6 classes of object
predictor = DefaultPredictor(cfg)

def get_bbox_list(outputs):
    import numpy 

    bbox_list=[]
    bbox_class_list=outputs["instances"].pred_classes     # get each predicted class from output, return a torch tensor
    bbox_cor_list=outputs["instances"].pred_boxes          # get each bounding box coordinate(xmin_ymin_xmax_ymax) from output, return a torch tensor
    bbox_class_list=bbox_class_list.cpu().numpy()         # convert class to numpy 
    #print(bbox_class_list)
    new_list=[]
    for i in bbox_cor_list:                               #conver coordinate to numpy
        i=i.cpu().numpy()
        #print(type(i))
        new_list.append(i)
    #print(new_list)
    bbox_cor_list=new_list


    for i in range(len(bbox_class_list)):                # combine to a new list
        #temp_dict=(dict(zip(bbox_class_list[i],bbox_cor_list[i])))
        temp_dict={'class':bbox_class_list[i],'coordinate':bbox_cor_list[i]}  # store each class and corresponding coordinate to dict
        bbox_list.append(temp_dict)

    return bbox_list

def save_bbox_image(bbox_list,read_img_dir,save_img_dir):
    from PIL import Image        #import  image

    counter_=1
    img=Image.open(read_img_dir)   #read the orignal predicted image
    for i in bbox_list:
    
        file_name=str(counter_)+'.jpg'
        path=save_img_dir+'/'+file_name
        coordinate=i.get('coordinate')  # get bounding box coordinate for corping
        coordinate=tuple(coordinate)# bbox coordinate should be in list when out put from detectron and change to tuple
    
        crop_img=img.crop(coordinate)
        crop_img.show()
        crop_img.save(path)
        counter_+=1
    return

image_path='/content/ikea-a-bed-that-folds-away-to-be-a-sofa-by-day__1364309472525-s4.jpg'

im = cv2.imread(image_path)
outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format
#v = Visualizer(im[:, :, ::-1],
#                metadata=furniture_data_metadata, 
#                scale=0.5 
                  
#                )
#out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
#cv2_imshow(out.get_image()[:, :, ::-1])

bbox_list=get_bbox_list(outputs) # get each bbx info
save_bbox_image(bbox_list,bbox_list,img_path,save_img_dir)